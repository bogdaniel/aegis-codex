---
description: "Performance standards: efficiency without breaking correctness."
required: false
category: "topic"
subcategory: "performance"
globs:
  - "src/**"
  - "app/**"
  - "services/**"
  - "domain/**"
---

[SOURCE OF TRUTH]
- Editable source: `rules/33-performance.mdc`
- Generated/consumed copy: `.cursor/rules/33-performance.mdc` (keep references intact)

[PERFORMANCE BASELINE]
- Measure first with realistic workloads; address hot paths/N+1s only; prefer simplicity over clever micro-optimizations.
- Complexity: choose appropriate data structures; avoid accidental O(n^2+); batch external calls.
- Application/API: enforce limits per request (page/batch size); paginate all lists (cursor preferred for large sets); avoid unbounded work.
- Data/storage: index common queries; reuse pooled connections; set timeouts; avoid long transactions; compress/stream large payloads.
- Concurrency: bounded concurrency with back-pressure; timeouts/retries with jitter and circuit breakers for remote calls; avoid unbounded goroutines/threads/promises.
- Caching: safe caching for idempotent reads; define TTL and invalidation; respect consistency.
- Resource management: close/cleanup handles; cap memory/FD/thread use; avoid per-request allocations in tight loops.

[PERFORMANCE & TRUST TIERS]
- **Tier H contexts** (from 36-architecture.mdc):
  - Do NOT introduce complexity (e.g., caching, sharding) into Tier H contexts unless justified by SLO.
  - Prefer simple, auditable designs.
- Architectural decisions in 36-architecture.mdc MUST consider the performance implications in this file.

[COMPLEXITY ANALYSIS]

### Time Complexity
- **O(1):** Hash lookups, array indexing (preferred for hot paths).
- **O(log n):** Binary search, balanced trees (acceptable for large datasets).
- **O(n):** Linear scans, single loops (acceptable if n is bounded).
- **O(n log n):** Sorting, divide-and-conquer (acceptable for preprocessing).
- **O(n²):** Nested loops, cartesian products (avoid in hot paths; batch or index).
- **O(2ⁿ):** Exponential algorithms (avoid; use dynamic programming or heuristics).

**Examples:**
```typescript
// ❌ BAD: O(n²) nested loop
for (const user of users) {
  for (const order of orders) {
    if (order.userId === user.id) { /* ... */ }
  }
}

// ✅ GOOD: O(n) with Map
const orderMap = new Map(orders.map(o => [o.userId, o]));
for (const user of users) {
  const order = orderMap.get(user.id);
  if (order) { /* ... */ }
}
```

### Space Complexity
- **O(1):** Constant space (preferred).
- **O(n):** Linear space (acceptable if bounded).
- **O(n²):** Quadratic space (avoid; use streaming or generators).

**Examples:**
```typescript
// ❌ BAD: O(n²) space (all combinations)
const pairs = [];
for (const a of items) {
  for (const b of items) {
    pairs.push([a, b]);
  }
}

// ✅ GOOD: O(1) space (generator)
function* pairs(items: Item[]) {
  for (const a of items) {
    for (const b of items) {
      yield [a, b];
    }
  }
}
```

### N+1 Query Problem
**Symptom:** One query to fetch list, then N queries to fetch related data.
**Fix:** Use eager loading, batch loading, or joins.

**Examples:**
```typescript
// ❌ BAD: N+1 queries
const orders = await orderRepository.findAll();
for (const order of orders) {
  const user = await userRepository.findById(order.userId); // N queries
}

// ✅ GOOD: Eager loading
const orders = await orderRepository.findAllWithUsers(); // 1 query with JOIN

// ✅ GOOD: Batch loading
const userIds = orders.map(o => o.userId);
const users = await userRepository.findByIds(userIds); // 1 batch query
const userMap = new Map(users.map(u => [u.id, u]));
```

[MICROSERVICES PATTERNS]

### Service Mesh
- **Purpose:** Handle cross-cutting concerns (load balancing, retries, circuit breakers, mTLS).
- **Patterns:** Istio, Linkerd, Consul Connect.
- **When to use:** Multiple services with complex inter-service communication.
- **Benefits:** Centralized observability, security, traffic management.

### API Gateway
- **Purpose:** Single entry point for clients; routing, authentication, rate limiting.
- **Patterns:** Kong, AWS API Gateway, Azure API Management.
- **When to use:** Multiple services exposed to clients; need unified API.
- **Benefits:** Centralized auth, rate limiting, request/response transformation.

### Distributed Tracing
- **Purpose:** Track requests across service boundaries.
- **Patterns:** OpenTelemetry, Jaeger, Zipkin.
- **When to use:** Debugging latency issues in microservices.
- **Benefits:** End-to-end visibility, latency analysis, dependency mapping.

### Database Optimization

#### Indexing
- **Create indexes** on frequently queried columns (WHERE, JOIN, ORDER BY).
- **Composite indexes** for multi-column queries (order matters).
- **Avoid over-indexing** (slows writes; use selectively).

**Examples:**
```sql
-- ✅ GOOD: Index on frequently queried column
CREATE INDEX idx_user_email ON users(email);

-- ✅ GOOD: Composite index for multi-column query
CREATE INDEX idx_order_user_date ON orders(user_id, created_at);
```

#### Query Optimization
- **Use EXPLAIN/EXPLAIN ANALYZE** to understand query plans.
- **Avoid SELECT *** (fetch only needed columns).
- **Use LIMIT/OFFSET** or cursor-based pagination for large result sets.
- **Avoid correlated subqueries** (use JOINs or CTEs).

**Examples:**
```sql
-- ❌ BAD: SELECT * (fetches unnecessary columns)
SELECT * FROM users WHERE email = ?;

-- ✅ GOOD: Select only needed columns
SELECT id, email, name FROM users WHERE email = ?;

-- ❌ BAD: Correlated subquery
SELECT * FROM orders WHERE user_id IN (
  SELECT id FROM users WHERE created_at > ?
);

-- ✅ GOOD: JOIN
SELECT o.* FROM orders o
JOIN users u ON o.user_id = u.id
WHERE u.created_at > ?;
```

### Caching Patterns

#### Cache-Aside (Lazy Loading)
- **Pattern:** Application checks cache; if miss, fetches from DB and populates cache.
- **Use when:** Read-heavy workloads; data can be stale.
- **Example:**
```typescript
async function getUser(id: string): Promise<User> {
  let user = await cache.get(`user:${id}`);
  if (!user) {
    user = await db.users.findById(id);
    await cache.set(`user:${id}`, user, { ttl: 3600 });
  }
  return user;
}
```

#### Write-Through
- **Pattern:** Write to cache and DB simultaneously.
- **Use when:** Need strong consistency; write-heavy workloads.
- **Example:**
```typescript
async function updateUser(id: string, data: UserData): Promise<void> {
  const user = await db.users.update(id, data);
  await cache.set(`user:${id}`, user, { ttl: 3600 });
}
```

#### Cache Invalidation
- **Pattern:** Invalidate cache on data changes.
- **Use when:** Data changes frequently; need freshness.
- **Example:**
```typescript
async function deleteUser(id: string): Promise<void> {
  await db.users.delete(id);
  await cache.del(`user:${id}`);
}
```

[ENHANCED @PERF-OPTIMIZER PROMPTS]

- **Profiling first:** Always profile before optimizing; identify actual bottlenecks.
- **Complexity analysis:** State time/space complexity of optimizations.
- **Evidence-based:** Provide benchmarks or load-test results; avoid speculative claims.
- **Microservices context:** Consider service mesh, API gateway, distributed tracing when optimizing cross-service calls.
- **Database optimization:** Check for N+1 queries, missing indexes, inefficient queries.
- **Caching strategy:** Recommend appropriate caching patterns (cache-aside, write-through, invalidation).

[VERIFICATION]
- Provide benchmark/load-test/check (e.g., `go test -bench .`, `npm run bench`, `wrk -t2 -c10 -d30s http://...`) and expected latency/throughput target.

**See also:**
- `.cursor/rules/3A-anti-patterns.mdc` — Performance anti-patterns (premature optimization, N+1 queries)
- `.cursor/rules/20-agents.mdc` — `@perf-optimizer` agent with complexity/database/caching focus
- `.cursor/rules/36-architecture.mdc` — Architecture rules (performance implications, Tier H constraints)
- `docs/test-scenarios.md` — Test scenarios for performance optimization
- `test/example-app/` — Canonical demo (performance patterns in Clean Architecture)
